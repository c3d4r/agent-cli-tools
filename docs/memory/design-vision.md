# Design Vision & Discussion Notes

## North Star

Building CLI tools for agents (and humans) that reduce repetitive/mechanical work so agent time goes to judgment and problem-solving. Inspired by Naur's "Programming as Theory Building" ([PDF](https://pages.cs.wisc.edu/~remzi/Naur.pdf)) — the goal is a **theory persistence layer** for codebases.

Naur's insight is real but his conclusion is too strong — people *do* reconstruct theories, it's just expensive. The goal is to make it cheaper.

Guiding principle: **make the implicit explicit, the ephemeral persistent, the structural mechanical.**

Design philosophy: start simple, ship, evaluate, iterate. Unix traditions. Intuitive enough that agents can use tools without docs/training.

## Current Tools

- `e` — content-addressed file editor (line + content matching)
- `lsp-cli` — LSP client CLI for semantic code navigation

## Key Design Decisions & Ideas

### Fractal Project Description (likely next step)

Progressive disclosure for project structure:

- Level 0: language, build cmd, test cmd, entry points (~5 lines)
- Level 1: module boundaries, public API surface per module
- Level 2: per-module internal structure, key types, data flow
- Level 3: function-level detail, call relationships

Principles:
- Generated by **code, not agent** — deterministic, fast, cacheable
- Pre-generated before an agent touches the repo
- "Like maven but not ugly, more semantic"
- Agent semantic annotations can layer on top, pinned to git SHAs
- Format should look like something a human would write anyway, but be machine-parseable
- Markdown with conventions beats XML; directory structure beats config files

### Unified Content-Based Reference Format

`e` and `lsp-cli` should share reference conventions. Content-based refs over line numbers — more stable, closer to how people think about code.

Possible syntax:
```
file.go:func:HandleRequest        # function scope
file.go:"return nil"              # content match (first occurrence)
file.go:func:HandleRequest+3      # 3 lines into function body
```

Could also serve as hyperlink targets (e.g. PlantUML diagrams → code).

### Agent-First Code

Code written for both humans and machines, with machine readability as a first-class constraint:

- Annotations/tags as structured metadata, not just comments
- Machine-parseable but human-natural (markdown with conventions > XML)
- Directory structure as contract, not just convention
- Naming conventions become contracts, not just style preferences
- Module boundaries declared, not inferred
- Every abstraction layer links back to the concrete layer below

### Other Ideas Discussed

- **Diff impact analysis**: given a proposed change, report which tests cover the changed code, which callers are affected, whether the change is backwards-compatible. The gap between "I made an edit" and "I'm confident it's correct."
- **Tagged regions**: concept tagging for code sections. Enables structured "semantic search" without RAG. "Where is auth error handling?" becomes a query across two tag dimensions.
- **Decision log**: "we chose X over Y because Z" — hardest to automate, highest value for agents picking up mid-project.
- **Process watchers / subagents**: for build/test feedback loops. Agents struggle with process management. Like a cerebellum — background tasks with minimal conscious awareness.
- **Persistent understanding**: structured text files version-pinned to commits as pragmatic "memory." Simpler and more inspectable than KV cache / neural approaches. Gets 80% of the value and is portable across different agents.

### Semantic Project Summary

Two layers:
1. **Structural index** (code-generated): exports, dependencies, call graph, type relationships. Deterministic, trustworthy, fast.
2. **Semantic annotations** (agent-generated, cached): "this module handles authentication." Judgment calls, layered on top, version-pinned to commits.

## Design Constraints

- Zero external dependencies (stdlib only)
- Single Go module, single version tag
- Cross-compiled static binaries with CGO_ENABLED=0
- Tools should feel natural given unix conventions

## What Agents Actually Do When Starting a Repo

Observed pattern (useful for knowing what to optimize):

1. **Orientation**: read CLAUDE.md/README, `ls` root, check `git log`
2. **Build & verify**: run build, run tests, check for linters/formatters
3. **Narrow to task**: grep/ripgrep for keywords, glob for file names, read files, LSP navigation
4. **Edit**: make changes
5. **Verify**: rebuild, retest

Most time goes to building the mental model (steps 1-3) and verifying correctness (step 5). The actual editing (step 4) is the easy part. Tools that accelerate comprehension and verification have the highest leverage.
